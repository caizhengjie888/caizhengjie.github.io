[{"title":"HBase的应用场景及架构原理","url":"/posts/2845542846/","content":"## 一、HBase在实际业务场景中的应用\n<!-- more -->\n HBase是一个构建在HDFS上的分布式列存储系统；HBase是Apache Hadoop生态系统中的重要一员，主要用于海量结构化数据存储\nHBase能做什么？\n\n - 海量数据存储\n - 准实时查询\n\n举例说明HBase在实际业务场景中的应用\n\n - 交通\n - 金融\n - 电商\n - 移动\n\n## 二、HBase的特点\n\n - 容量大：HBase单表可以有百亿行，百万列，数据矩阵横向和纵向两个纬度所支持的数据量级别都非常具有弹性\n - 稀疏性：为空的列并不占用存储空间，表可以设计的非常稀疏\n - 多版本：HBase每一列的数据存储有多个Version\n - 面向列：HBase是面向列的存储和权限控制，并支持独立检索。列式存储，其数据在表中是按照某列存储的，这样在查询只需要少数几个字段的时候，能大大减少读取的数据量。\n - 扩展性：底层依赖于HDFS\n - 高可靠性：WAL机制保证了数据写入时不会因集群异常而导致写入数据丢失：Replication机制保证了在集群出现严重的问题时，数据不会发生丢失或损坏。而HBase底层使用HDFS，HDFS本身也有备份。\n - 高性能：底层的LSM数据结构和RowKey有序排列等架构上的独特设计，使得HBase具有非常的写入性能。region切分、主键索引和缓存机制使得HBase在海量数据下具备一定的随机读取性能，该性能针对Rowkey的查询能够达到毫秒级。\n\n## 三、HBase数据模型并举例说明\n### （1）逻辑存储模型\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620144549427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620144556770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620145009724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620145026967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n RowKey：Hbase使用Rowkey来唯一的区分某一行的数据。\n Column Family（列族）：Hbase通过列族划分数据的存储，列族下面可以包含任意多的列，实现灵活的数据存取。Hbase的列族不是越多越好，官方推荐的是列族最好小于或者等于3。我们使用的场景一般是1个列族。\n Time Stamp（时间戳）：TimeStamp对Hbase来说至关重要，因为它是实现Hbase多版本的关键。在Hbase中使用不同的timestame来标识相同rowkey行对应的不通版本的数据。\nCell：HBase 中通过 rowkey 和 columns 确定的为一个存储单元称为 cell。每个 cell 都保存着同一份 数据的多个版本。版本通过时间戳来索引。\n\n### （2）物理存储模型\nHbase的Table中的所有行都按照row key的字典序排列。Table 在行的方向上分割为多个Region。Region按大小分割的，每个表开始只有一个region，随 着数据增多，region不断增大，当增大到一个阀值的时候， region就会等分会两个新的region，之后会有越来越多的 region。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020062015133549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620151359707.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)Region是HBase中分布式存储和负载均衡的最小单元。 不同Region分布到不同RegionServer上。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620151423495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70) Region虽然是分布式存储的最小单元，但并不是存储 的最小单元。Region由一个或者多个Store组成，每个store保存一个 columns family。每个Strore又由一个memStore和0至多个StoreFile组成。memStore存储在内存中，StoreFile存储在HDFS上。 \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620151508530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n## 四、HBase基本架构\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620151645506.png)\n包括了HMaster、HRegionSever、HRegion、HLog、Store、MemStore、StoreFile、HFile等。HBase底层依赖HDFS，通过DFS Cilent进行HDFS操作。HMaster负责把HRegion分配给HRegionServer，每一个HRegionServer可以包含多个HRegion，多个HRegion共享HLog，HLog用来做灾难恢复。每一个HRegion由一个或多个Store组成，一个Store对应表的一个列族，每个Store中包含与其对应的MemStore以及一个或多个StoreFile（是实际数据存储文件HFile的轻量级封装），MemStore是在内存中的，保存了修改的数据，MemStore中的数据写到文件中就是StoreFile。\n\n### （1）HMaster\n HMaster的主要功能有：\n\n - 把HRegion分配到某一个RegionServer。\n - 有RegionServer宕机了，HMaster可以把这台机器上的Region迁移到active的RegionServer上。\n - 对HRegionServer进行负载均衡。\n - 通过HDFS的dfs client接口回收垃圾文件（无效日志等）\n注：HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。\n\n### （2）HRegionServer\nHRegionServer的主要功能有：\n - 维护HMaster分配给它的HRegion，处理对这些HRegion的IO请求，也就是说客户端直接和HRegionServer打交道。（从图中也能看出来）\n - 负责切分正在运行过程中变得过大的HRegion\n\n### （3）基本架构\nHBase构建在HDFS之上，其组件包括 Client、zookeeper、HDFS、Hmaster以及HRegionServer。Client包含访问HBase的接口，并维护cache来加快对HBase的访问。Zookeeper用来保证任何时候，集群中只有一个master，存贮所有Region的寻址入口以及实时监控Region server的上线和下线信息。并实时通知给Master存储HBase的schema和table元数据。HMaster负责为Region server分配region和Region server的负载均衡。如果发现失效的Region server并重新分配其上的region。同时，管理用户对table的增删改查操作。Region Server 负责维护region，处理对这些region的IO请求并且切分在运行过程中变得过大的region。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620152844598.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\nHBase 依赖ZooKeeper，默认情况下，HBase 管理ZooKeeper 实例。比如， 启动或者停止ZooKeeper。Master与RegionServers 启动时会向ZooKeeper注册。因此，Zookeeper的引入使得 Master不再是单点故障。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620152948461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n Client每次写数据库之前，都会首先血Hlog日志。记录写操作。如果不做日志记录，一旦发生故障，操作将不可恢复。HMaster一旦故障，Zookeeper将重新选择一个新的Master 。无Master过程中，数据读取仍照常进行。但是，无master过程中，region切分、负载均衡等无法进行。RegionServer出现故障的处理原理是定时向Zookeeper汇报心跳，如果一旦时 间内未出现心跳HMaster将该RegionServer上的Region重新分配到其他RegionServer上。失效服务器上“预写”日志由主服务器进行分割并派送给新的 RegionServer 。Zookeeper是一个可靠地服务，一般配置3或5个Zookeeper实例。 \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620152948339.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n  寻找RegionServer定位的顺序是ZooKeeper --ROOT-(单Region) -.META. -用户表 。如上图所示。-ROOT- 表包含.META.表所在的region列表，该表只会有一 个Region。 Zookeeper中记录了-ROOT-表的location。  .META. 表包含所有的用户空间region列表，以及 RegionServer的服务器地址。 \n\n\n参考文章：\n\n - [https://www.jianshu.com/p/9d3d388eae19?utm_source=oschina-app](https://www.jianshu.com/p/9d3d388eae19?utm_source=oschina-app)\n - [https://blog.csdn.net/tianyeshiye/article/details/80768072](https://blog.csdn.net/tianyeshiye/article/details/80768072)","tags":["Hadoop"],"categories":["Hadoop学习指南"]},{"title":"Centos7下HBase安装与配置（亲测！）","url":"/posts/3651396382/","content":"## Centos7下Hadoop完全分布式安装\n - 电脑系统：macOS 10.15.4 \n - 虚拟机软件：Parallels Desktop14 \n - Hadoop各节点节点操作系统：CentOS 7\n - JDK版本：jdk1.8.0_162 \n - HBase版本：hbase-1.2.0-cdh5.9.3\n\nhbase的下载源地址：\n官网：\n[https://archive.cloudera.com/cdh5/cdh/5/](https://archive.cloudera.com/cdh5/cdh/5/)\nCDH版本：\n[https://archive.apache.org/dist/hadoop/](https://archive.apache.org/dist/hadoop/)\n## 第一步：安装软件\n### （1）上传文件\n将本机的安装包上传到虚拟机node1，上传方式：\n\n```bash\nscp 本机的文件绝对路径 caizhengjie@10.211.55.49:/opt/Hadoop\n```\n### （2）解压文件\n上传成功之后需要对文件赋予权限\n\n```bash\nchmod u+x hbase-1.2.0-cdh5.9.3.tar.gz\n```\n解压文件：\n\n```bash\ntar -zxvf hbase-1.2.0-cdh5.9.3.tar.gz\n```\n创建软链接：\n```bash\nln -s hbase-1.2.0-cdh5.9.3 hbase\n```\n\n## 第二步：配置环境变量\n\n```bash\nvim ~/.bashrc\n```\n然后添加以下内容，注意三台虚拟机都需要配置环境变量\n```bash\nexport HBASE_HOME=/opt/Hadoop/hbase\nexport PATH=$HBASE_HOME/bin:$PATH\n```\n最后使之生效\n\n```bash\nsource ~/.bashrc\n```\n\n## 第三步：修改配置文件\n### （1）修改hbase-env.sh配置文件\n**第一步**\n进入到conf目录下\n\n```bash\ncd /opt/Hadoop/hbase/conf\nvim hbase-env.sh\n```\n找到**export JAVA_HOME**，将前面的**#**去掉\n修改为：\n\n```bash\nexport JAVA_HOME=/opt/Hadoop/jdk1.8.0_162\n```\n**第二步**\n接着找到图中红框的部分，将它注释掉\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620120557696.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n原理解释： 启动hbase的时候报出警告\n\n```bash\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0\n```\n查看配置文件\n #Configure PermSize. Only needed in JDK7. You can safely remove it for JDK8+\n 这里我用的是jdk8，按照上面的操作将那两行注释掉就不会报出警告了。\n **第三步**\n 找到**export HBASE_MANAGES_ZK**，将前面的#去掉\n 修改为：\n```bash\nexport HBASE_MANAGES_ZK=false\n```\n原理解释：这里我们不用自带的zookeeper，选择用我们自己的zookeeper\n[想查看zookeeper安装的详细操作点这里！](https://blog.csdn.net/weixin_45366499/article/details/106782337)\n\n这样hbase-env.sh文件就配置成功了\n### （2）修改hbase-site.xml配置文件\n首先进入到/opt/Hadoop/hbase目录下\n\n```bash\nmkdir zookeeper-data\n```\n创建zookeeper-data目录文件\n\n```bash\nvim hbase-site.xml\n```\n添加如下内容\n\n```bash\n<configuration>\n         <!-- Hbase的数据保存在HDFS对应的目录下 -->\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://node1:8020/hbase</value>\n        </property>\n\n        <!-- 是否是分布式环境 -->\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n\n        <!-- 配置ZK的地址，3个节点都启用Zookeeper -->\n        <property>\n                <name>hbase.zookeeper.quorum</name>\n                <value>node1,node2,node3</value>\n        </property>\n\n        <!-- 冗余度 -->\n        <property>\n                <name>dfs.replication</name>\n                <value>2</value>\n        </property>\n\n        <!-- 主节点和从节点允许的最大时间误差 -->\n        <property>\n                <name>hbase.master.maxclockskew</name>\n                <value>180000</value>\n        </property>\n\n        <!-- zookeeper数据目录 -->\n        <property>\n                <name>hbase.zookeeper.property.dataDir</name>\n                <value>/opt/Hadoop/hbase/zookeeper-data</value>\n        </property>\n\t\t<!-- 设置网页端口号 -->\n        <property>\n                <name>hbase.master.info.port</name>\n                <value>60010</value>\n        </property>\n</configuration>\n```\n根据自己的配置适当修改\n\n### （3）修改regionservers 文件\n\n```bash\ncd /opt/Hadoop/hbase/conf\nvim regionservers\n```\n将下面的内容换成\n\n```bash\nnode1\nnode2\nnode3\n```\n### （4）配置backup-masters （可选）\n为了增加hbase集群的可用性，可以为hbase增加多个backup master。当master挂掉后，backup master可以自动接管整个hbase的集群。配置backup master的方式是在hbase的conf下增加文件backup-masters，在该文件里面增加backup master的机器列表，每台机器一条记录。\n\n```bash\ncd /opt/Hadoop/hbase/conf\ntouch backup-masters\n```\n在里面添加内容\n\n```bash\nnode2\n```\n## 第四步：分发配置文件\n将node1的hbase-1.2.0-cdh5.9.3和hbase-1.2.0-cdh5.9.3.tar.gz文件分发到node2和node3上\n\n```bash\nscp -r hbase-1.2.0-cdh5.9.3 hbase-1.2.0-cdh5.9.3.tar.gz caizhengjie@node2:/opt/Hadoop/\nscp -r hbase-1.2.0-cdh5.9.3 hbase-1.2.0-cdh5.9.3.tar.gz caizhengjie@node3:/opt/Hadoop/\n```\n分别在node2和node3上创建软连接\n\n```bash\nln -s hbase-1.2.0-cdh5.9.3 hbase\n```\n## 第五步：启动与检测\n在启动HBase之前要先把三台机的zookeeper给启动起来，不然会出现刚启动hbase的进程就消失，我通过查看日志文件，找出的原因是zookeeper没有启动。报错信息如下：\n\n```bash\n020-06-20 11:31:30,550 INFO  [main-SendThread(node1:2181)] zookeeper.ClientCnxn: Opening socket connection to server node1/10.211.55.59:2181. Will not attempt to authenticate using SASL (unknown error)\n2020-06-20 11:31:30,550 WARN  [main-SendThread(node1:2181)] zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect\njava.net.ConnectException: 拒绝连接\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)\n\tat org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)\n2020-06-20 11:31:30,652 INFO  [main-SendThread(node2:2181)] zookeeper.ClientCnxn: Opening socket connection to server node2/10.211.55.60:2181. Will not attempt to authenticate using SASL (unknown error)\n2020-06-20 11:31:30,652 ERROR [main] zookeeper.RecoverableZooKeeper: ZooKeeper create failed after 4 attempts\n2020-06-20 11:31:30,652 ERROR [main] master.HMasterCommandLine: Master exiting\njava.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster. \n\tat org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2486)\n\tat org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:231)\n\tat org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:137)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n\tat org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:127)\n\tat org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2496)\nCaused by: org.apache.hadoop.hbase.ZooKeeperConnectionException: master:600000x0, quorum=node1:2181,node2:2181,node3:2181, baseZNode=/hbase Unexpected KeeperException creating base node\n\tat org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.createBaseZNodes(ZooKeeperWatcher.java:206)\n\tat org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:187)\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:594)\n\tat org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:420)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2479)\n\t... 5 more\nCaused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)\n\tat org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.createNonSequential(RecoverableZooKeeper.java:565)\n\tat org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.create(RecoverableZooKeeper.java:544)\n\tat org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:1204)\n\tat org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:1182)\n\tat org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.createBaseZNodes(ZooKeeperWatcher.java:194)\n\t... 13 more\n```\n下面开始启动HBase，在node1上输入命令：\n\n```bash\nstart-hbase.sh\n```\n查看jps\nnode1会出现：\n\n```bash\n[caizhengjie@node1 ~]$ jps\n2769 SecondaryNameNode\n4804 QuorumPeerMain\n4984 HMaster\n6202 Jps\n2475 NameNode\n5244 HRegionServer\n2606 DataNode\n```\nnode2会出现：\n\n```bash\n[caizhengjie@node2 Hadoop]$ jps\n3427 HRegionServer\n2215 DataNode\n3659 HMaster\n3340 QuorumPeerMain\n4302 Jps\n```\nnode3会出现：\n\n```bash\n[caizhengjie@node3 logs]$ jps\n2784 QuorumPeerMain\n3431 Jps\n2027 DataNode\n2878 HRegionServer\n```\n则表示HBase安装成功，这里有的人会发现我的node1和node2出现了两个HMaster，因为我设置了backup-masters。\n\n下面我来访问一下网页：[http://10.211.55.59:60010/master-status](http://10.211.55.59:60010/master-status)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620124248608.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620124248604.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n一切正常！\n## 第六步：常见问题\n在启动HBase的过程中会出现一些问题，不过也不要被这些问题吓到，通过查看日志文件，都是可以找到解决方案的。\n**我遇到的第一个问题：No space left on device**\n意思是磁盘空间不够，之前我安装的Hadoop，Hbase都是安装在/home/caizhengjie/目录下面的，但是随着文件数量新增，出现了磁盘空间不够，我通过`df -h`命令查看磁盘空间，果然不够\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200620125002744.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n由图片可以看出home目录下的磁盘空间只有2.6G，而根目录下的空间有27G，因为是虚拟机，所以我可以在后面继续扩磁盘空间。因此我只好把Hadoop那些文件全部转移到/opt/目录下，这下就解决了磁盘不足的问题。\n\n**我遇到的第二个问题：运行HBase报SLF4J: Class path contains multiple SLF4J bindings**\n主要原因是slf4j-log4j12.jar包和Hadoop中的slf4j-log4j12.jar包冲突导致的\n解决方法是将/opt/Hadoop/hbase/lib中的slf4j-log4j12.jar包删除即可，但是不要将三台机的slf4j-log4j12.jar包都给删掉，不然又会报错：**Failed to load class org.slf4j.impl.StaticLoggerBinder**，我是把node1和node2的给删除掉了，留下node3\n\n参考文章：\n\n - 解决slf4j问题\n - [http://www.slf4j.org/codes.html](http://www.slf4j.org/codes.html)\n - 解决Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0问题\n - [https://www.cnblogs.com/QuestionsZhang/p/10281839.html](https://www.cnblogs.com/QuestionsZhang/p/10281839.html)\n - 解决SLF4J: Class path contains multiple SLF4J bindings问题\n - [https://blog.csdn.net/qq_27575895/article/details/90238240](https://blog.csdn.net/qq_27575895/article/details/90238240)\n - 解决HBase安装问题\n - [https://www.jianshu.com/p/ecae88481db2](https://www.jianshu.com/p/ecae88481db2)\n - 解决Linux磁盘空间不足的问题\n - [https://blog.csdn.net/u010455714/article/details/77711834](https://blog.csdn.net/u010455714/article/details/77711834)\n\n## 总结\n对于新手安装HBase来说，就是照着其他的模版来也未必能不踩坑的顺利安装好，这里我就总结两点经验。第一：坚持！一定要坚持！行百里者半九十。第二：一定要多看日志文件！这一点非常重要，因为并不是所有的报错信息在网上都能找到，只有看到报错信息才能知道哪里的问题。通常对于小白来说，什么是日志信息？日志信息说白了就是所有的报错信都在日志信息里面。\n如何查看日志信息？通常来说可以使用more或cat命令，日志信息在/opt/Hadoop/hbase/logs目录下\n可以通过下面的命令来查看日志信息\n```bash\ncat hbase-caizhengjie-master-node1.log \n```\n","tags":["Hadoop"],"categories":["Hadoop学习指南"]},{"title":"Centos下ZooKeeper安装部署配置（集群模式）","url":"/posts/4170185227/","content":"## 第一步：准备文件\n<!-- more -->\n### （1）上传文件\n将zookeeper压缩文件上传至node1中，Mac系统上传方式可以直接通过终端scp命令，Windows系统可以通过其他的上传工具。上传方式为：\n\n```bash\nscp /自己电脑本机路径/zookeeper-3.4.13.tar.gz caizhengjie@10.211.55.59:/opt/Hadoop\n```\n### （2）解压文件\n上传成功之后需要对文件赋予权限\n\n```bash\nchmod u+x zookeeper-3.4.13.tar.gz\n```\n解压文件：\n\n```bash\ntar -zxvf zookeeper-3.4.13.tar.gz\n```\n创建软链接：\n\n```bash\nln -s zookeeper-3.4.13 zookeeper\n```\n## 第二步：修改配置文件\n### （1）重命名文件\n在安装zookeeper的时候我们要去修改zookeeper预装是conf目录下面的zoo_sample.cfg这个文件，首先我们要做的事就是重命名这个文件。在目录/opt/Hadoop/zookeeper/conf下，将zoo_sample.cfg改名为zoo.cfg文件，这一步**非常重要**，不修改的话会出现下面的问题：\n\n```bash\nZooKeeper JMX enabled by default\nUsing config: /home/caizhengjie/zookeeper/bin/../conf/zoo.cfg\ngrep: /home/caizhengjie/zookeeper/bin/../conf/zoo.cfg: 没有那个文件或目录\nmkdir: 无法创建目录\"\": 没有那个文件或目录\nStarting zookeeper ... /home/caizhengjie/zookeeper/bin/zkServer.sh:行149: /zookeeper_server.pid: 权限不够\nFAILED TO WRITE PID\n```\n这是第一个坑！\n则我们需要修改文件名：\n```bash\nmv zoo_sample.cfg  zoo.cfg\n```\n\n### （2）创建tmp文件夹\n\n```bash\ncd /opt/Hadoop/zookeeper/\n```\n```bash\nmkdir tmp\n```\n```bash\ncd tmp\n```\n```bash\nmkdir data\n```\n### （3）创建myid文件\n```bash\ncd /opt/Hadoop/zookeeper/tmp/data\nvim myid\n```\n第一台主机node1添加内容：1\n**注意：一定要在刚才创建的data文件夹下在创建myid**\n如果直接在tmp文件夹下直接创建myid文件，查看zookeeper.out日志文件会报错\n\n```bash\nCaused by: java.lang.IllegalArgumentException: /opt/Hadoop/zookeeper/tmp/data/myid file is missing\n```\n这是第二个坑！\n\n### （4）修改配置文件\n修改zookeeper/conf下zoo.cfg文件\n\n```bash\nvim zoo.cfg\n```\n\n```bash\n#The number of milliseconds of each tick\ntickTime=2000\n#The number of ticks that the initial \n#synchronization phase can take\ninitLimit=5\n#The number of ticks that can pass between \n#sending a request and getting an acknowledgement\nsyncLimit=2\n#the directory where the snapshot is stored.\n#do not use /tmp for storage, /tmp here is just \n#example sakes.\n#**这个地方填写自己的路径**\ndataDir=/opt/Hadoop/zookeeper/tmp/data\n#the port at which the clients will connect\nclientPort=2181\n#the maximum number of client connections.\n#increase this if you need to handle more clients\n#maxClientCnxns=60 \n#服务器名称与地址:集群信息(服务器编号、服务器编号、服务器地址、LF通信端口、选举端口)\nserver.1=node1:2888:3888\nserver.2=node2:2888:3888\nserver.3=node3:2888:3888\n```\n## 第三步：配置环境变量\n配置环境变量：\n```bash\nvim ~/.bashrc\n```\n添加下面内容：\n```bash\nexport ZOOKEEPER_HOME=/opt/Hadoop/zookeeper\nexport PATH=$ZOOKEEPER_HOME/bin:$PATH\n```\n这里需要根据自己安装的路径来填写\n使之生效： \n\n```bash\nsource ~/.bashrc\n```\n## 第四步：分发文件\n### （1）分发文件\n在node1配置好文件之后，需要将文件分发到node2，node3机器下面。\n\n```bash\nscp -r zookeeper zookeeper-3.4.13 zookeeper-3.4.13.tar.gz caizhengjie@node2:/opt/Hadoop/\n```\n\n```bash\nscp -r zookeeper zookeeper-3.4.13 zookeeper-3.4.13.tar.gz caizhengjie@node3:/opt/Hadoop/\n```\n### （2）2、3机配置环境变量\n参考node1的配置方法\n### （3）修改myid文件\n前面在/opt/Hadoop/zookeeper/tmp/data/myid文件中，第一台主机添加内容：1\n则在node2和node3中分别按下面修改\n第二台主机添加内容：2\n第三台主机添加内容：3\n## 第五步：启动与查看运行状态\n按照上面的步骤全部配置完成之后，可以启动zookeeper\n启动命令(三台机同时启动)：\n\n```bash\nzkServer.sh start\n```\n关闭命令：\n\n```bash\nzkServer.sh stop\n```\n出现下面的情况则安装成功\n```bash\nZooKeeper JMX enabled by default\nUsing config: /opt/Hadoop/zookeeper/bin/../conf/zoo.cfg\nStarting zookeeper ... STARTED\n```\n检验jps进程\n```bash\n4616 Jps\n2041 QuorumPeerMain\n```\n查看运行状态（三台机同时）\n\n```bash\nzkServer.sh status\n```\nnode1\n```bash\nZooKeeper JMX enabled by default\nUsing config: /opt/Hadoop/zookeeper/bin/../conf/zoo.cfg\nMode: follower\n```\nnode2\n```bash\nZooKeeper JMX enabled by default\nUsing config: /opt/Hadoop/zookeeper/bin/../conf/zoo.cfg\nMode: leader\n```\nnode3\n```bash\nZooKeeper JMX enabled by default\nUsing config: /opt/Hadoop/zookeeper/bin/../conf/zoo.cfg\nMode: follower\n```\n会发现其中有一台机器是leader，其他两台机器是follower\n到这里zookeeper集群模式就安装成功了！\n\n总结：如果运行出错，多看zookeeper.out日志文件\n","tags":["Hadoop"],"categories":["Hadoop学习指南"]},{"title":"Hadoop常用命令","url":"/posts/2985237682/","content":"## 一、前述\n### （1）启动Hadoop所有进程\n**start-all.sh等价于start-dfs.sh + start-yarn.sh**\n<!-- more -->\n但是一般不推荐使用start-all.sh(因为开源框架中内部命令启动有很多问题)。\n### （2）单进程启动\n启动HDFS：\n```bash\nsbin/start-dfs.sh\n```\n```bash\n\tsbin/hadoop-daemons.sh --config .. --hostname .. start namenode ...\n    sbin/hadoop-daemons.sh --config .. --hostname .. start datanode ...\n    sbin/hadoop-daemons.sh --config .. --hostname .. start sescondarynamenode ...\n    sbin/hadoop-daemons.sh --config .. --hostname .. start zkfc ...         //\n```\n启动YARN：\n\n```bash\nsbin/start-yarn.sh\n```\n\n```bash\n\tlibexec/yarn-config.sh\n    sbin/yarn-daemon.sh --config $YARN_CONF_DIR  start resourcemanager\n    sbin/yarn-daemons.sh  --config $YARN_CONF_DIR  start nodemanager\n```\n### （3）关闭Hadoop所有进程\n关闭Hadoop服务：\n\n```bash\nstop-all.sh\n```\n\n### （4）格式化\n\n```bash\nhdfs namenode -format\n```\n\n## 二、常用命令\n### （1）查看指定目录下内容\nhdfs dfs –ls [文件目录]\n\n```bash\nhdfs dfs -ls -R  [文件目录]        //显式目录结构\n```\n\n```bash\nhdfs dfs -ls -d  [文件目录]          //返回的是path\n```\n\n```bash\nhdfs dfs -ls -h  [文件目录]          //h指的是“human-readable”，按照人性化的单位显示文件大小\n```\n\neg：hdfs dfs –ls /user/wangkai.pt\n### （2）查看某个文件\n\n```bash\nhdfs dfs –cat [file_path]\n```\n eg:hdfs dfs -cat /user/wangkai.pt/data.txt\n### （3）创建文件夹\n\n```bash\nhdfs dfs -mkdir [文件夹名称]\t\t\t//父目录存在的情况下\n```\n```bash\nhdfs dfs -mkdir -p [文件夹名称]\t   //父目录不存在（首先会创建父目录）\n```\n### （4）新建文件\n\n```bash\nhdfs dfs -touchz <paths>\n```\n### （5）将本地文件夹存储至HDFS\n\n```bash\nhdfs dfs -put [-f] [-p] [本地目录] [hdfs目录] \n```\n\n```bash\nhdfs dfs -copyFromLocal [-f] [-p] [-l] [本地目录] [hdfs目录] \n```\nput 或 copyFromLocal命令是将本地文件上传到HDFS。\n### （6）将本地文件移动到HDFS\n\n```bash\nhdfs dfs -moveFromLocal [本地目录] [hdfs目录]\n```\n使用这个命令，本地文件会被删除，移到了hdfs上\n\n### （7）下载文件\n\n```bash\nhdfs dfs -get [-p] [hdfs文件目录] [本地目录]\n```\n\n```bash\nhdfs dfs -copyToLocal [-p] [-ignoreCrc] [-crc] [hdfs文件目录] [本地目录]\n```\nget 或 copyToLocal 命令把文件从分布式系统复制到本地\n### （8）删除hadoop上指定文件或目录\n```bash\nhdfs  dfs –rm [hdfs文件地址]\n```\neg：hdfs dfs –rm /user/t/ok.txt\n\n```bash\nhdfs dfs -rm [-f] [-r] [hdfs文件目录]\n```\n-f：如果要删除的文件不存在，不显示错误信息。\n-r/R：级联删除目录下的所有文件和子目录文件。\n### （9）将hadoop上某个文件重命名\n使用mv命令：\n\n```bash\n hdfs dfs –mv  /user/test.txt  /user/ok.txt   （将test.txt重命名为ok.txt）\n```\n### （10）显示占用的磁盘空间大小\n\n```bash\nhdfs dfs -du [-s] [-h] <path>\n```\n按字节显示目录所占空间的大小。-s指的是显示指定目录下的文件总的大小，-h指的是“human-readable”，按照人性化的单位显示文件大小。\n### （11）HDFS中的文件复制\n\n```bash\nhdfs dfs -cp [-f] [-p | -p[topax]] [本地目录] [hdfs目录]\n```\n-f：如果目录文件存在，将强行覆盖。\n-p：将保存文件的属性。\n\n### （12）统计\n```bash\nhdfs dfs -count [-q] [-h] <path>\n```\n统计某个目录下的子目录与文件的个数及大小。统计结果包含目录数、文件数、文件大小。\n\n### （13）HDFS中的文件合并后下载到本地\n```bash\nhdfs dfs -getmerge [-nl] [hdfs文件目录] [本地目录]\n```\n### （14）将正在运行的hadoop作业kill掉\n\n```bash\n hadoop job –kill  [job-id]\n```\n### （15）安全模式\n安全模式(Safemode)是HDFS所处的一种特殊状态。处于这种状态时，HDFS只接受读数据请求，不能对文件进行写、删除等操作。\na 查看当前状态\n\n```bash\nhdfs dfsadmin -safemode get\n```\nb 进入安全模式\n\n```bash\nhdfs dfsadmin -safemode enter\n```\nc 强制离开安全模式\n\n```bash\nhdfs dfsadmin -safemode leave\n```\nd 一直等待，知道安全模式结束\n\n```bash\nhdfs dfsadmin -safemode wait\n```\n### （16）查看帮助\n\n```bash\nhdfs dfs -help \n```\n### （17）设置扩展属性\n\n```bash\nhdfs dfs -setfattr {-n name [-v value] | -x name} <path>\n```\n其中，采用hdfs dfs -setfattr -n name [-v value] | -x name <path> 可以设置属性。\n采用hdfs dfs -setfattr -x name <path>可以删除属性。\n-n：指定属性名称（设置属性时用）\n-v：指定属性值\n-x：指定属性的名称（删除属性时用）\n### （18）获取扩展属性\n\n```bash\nhdfs dfs -getfattr [-R] {-n name [-v value] | -x name} <path>\n```\n-n：指定属性名称\n-d：指定dump，即显示所有属性\n-e：指encoding，包含text、hex、base64等。\n### （19）HDFS管理命令\n**报告文件系统的基本信息和统计信息**\n```bash\nhdfs dfsadmin -report\n```\n**查看拓扑**\n```bash\nhdfs dfsadmin -printTopology\n```\n\n以上命令基本上为Hadoop的常用命令，除此之外均为其他命令。\n","tags":["Hadoop"],"categories":["Hadoop学习指南"]},{"title":"Java集合详解","url":"/posts/1169821274/","content":"## 一、集合简介\n集合本质是基于某种数据结构数据容器。常见的数据结构:数组(Array)、集(Set)、队列 (Queue)、链表(Linkedlist)、树(Tree)、堆(Heap)、栈(Stack)和映射(Map)等结构。\n<!-- more --> \nJava中提供了丰富的集合接口和类，它们来自于java.util包。如图所示是Java主要的集合接口和 类，从图中可见Java集合类型分为:Collection和Map，Collection子接口有:Set、Queue和List等接口。 每一种集合接口描述了一种数据结构。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200210174542205.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM2NjQ5OQ==,size_16,color_FFFFFF,t_70)\n在Java SE中List名称的类型有两个，一个是java.util.List，另外一个是java.awt.List。 java.util.List是一个接口，而java.awt.List是一个类，用于图形用户界面开 发，它是一个图形界面中的组件。学习Java中的集合，首先从两大接口入手，重点掌握List、Set和Map三个接口，熟悉这些接 口中提供的方法。然后再熟悉这些接口的实现类，并了解不同实现类之间的区别。\n\n## 二、List集合\nList集合中的元素是有序的，可以重复出现。List接口的实现类有:ArrayList 和 LinkedList。ArrayList是基于动态数组数据结构的实现，LinkedList 是基于链表数据结构的实现。ArrayList访问元素速度优于LinkedList，LinkedList占用的内存空间比较 大，但LinkedList在批量插入或删除数据时优于ArrayList。\n### （1）常用方法\nList接口继承自Collection接口，List接口中的很多方法都继承自Collection接口的。List接口中常用方法如下。\n01. 操作元素\nget(int index):返回List集合中指定位置的元素。\nset(int index, Object element):用指定元素替换List集合中指定位置的元素。\nadd(Object element):在List集合的尾部添加指定的元素。该方法是从Collection集合继承 过来的。\nadd(int index, Object element):在List集合的指定位置插入指定元素。 remove(int index):移除List集合中指定位置的元素。\nremove(Object element):如果List集合中存在指定元素，则从List集合中移除第一次出现的 指定元素。该方法是从Collection集合继承过来的。\nclear():从List集合中移除所有元素。该方法是从Collection集合继承过来的。\n 02. 判断元素\nisEmpty():判断List集合中是否有元素，没有返回true，有返回false。该方法是从 Collection集合继承过来的。\ncontains(Object element):判断List集合中是否包含指定元素，包含返回true，不包含返回 false。该方法是从Collection集合继承过来的。\n03. 查询元素\nindexOf(Object o):从前往后查找List集合元素，返回第一次出现指定元素的索引，如果\n此列表不包含该元素，则返回-1。\nlastIndexOf(Object o):从后往前查找List集合元素，返回第一次出现指定元素的索引，如果此列表不包含该元素，则返回-1。\n04. 其他\niterator():返回迭代器(Iterator)对象，迭代器对象用于遍历集合。该方法是从Collection 集合继承过来的。\nsize():返回List集合中的元素数，返回值是int类型。该方法是从Collection集合继承过来 的。\nsubList(int fromIndex, int toIndex):返回List集合中指定的 fromIndex(包括 )和 toIndex(不包括)之间的元素集合，返回值为List集合。\n代码如下：\n\n```java\npackage 集合.list集合;\nimport\tjava.util.ArrayList;\nimport java.util.List;\n//list集合：有序，重复\npublic class HelloWorld {\n    public static void main(String[] args) {\n//\n        List list = new ArrayList();\n        String b = \"B\";\n//       向集合中添加元素\n        list.add(\"A\");\n        list.add(b);\n        list.add(\"C\");\n        list.add(b);\n        list.add(\"D\");\n        list.add(\"E\");\n\n//        打印集合的元素个数\n        System.out.println(\"集合 size = \"+list.size());\n//        打印集合\n        System.out.println(list);\n//从前往后查找b元素\n        System.out.println(\"indexOf(\\\"B\\\") = \" +list.indexOf(b));\n//       从后往前查找\"B\"元素\n        System.out.println(\"lastindexOf(\\\"B\\\") = \" +list.lastIndexOf(b));\n        //删除集合中第一个\"B\"元素\n        list.remove(b);\n        System.out.println(\"remove(3)前: \"+list);\n        //判断集合中是否包含\"B\"元素\n        System.out.println(\"是否包含\\\"B\\\":\" + list.contains(b));\n\n        //删除集合第4个元素\n        list.remove(3);\n        System.out.println(\"remove(3)后: \" + list);\n\n        //判断集合是否为空\n        System.out.println(\"list集合是空的:\" + list.isEmpty());\n\n        System.out.println(\"替换前:\" + list); //替换集合第2个元素\n        list.set(1, \"F\");\n        System.out.println(\"替换后:\" + list);\n\n        //清空集合\n        list.clear();\n        System.out.println(list);\n\n        // 重新添加元素\n        list.add(1);// 发生自动装箱\n        list.add(3);\n        \n        int item = (Integer)list.get(0);//发生自动拆箱\n    }\n}\n```\n运行结果：\n\n```java\n集合 size = 6\n[A, B, C, B, D, E]\nindexOf(\"B\") = 1\nlastindexOf(\"B\") = 3\nremove(3)前: [A, C, B, D, E]\n是否包含\"B\":true\nremove(3)后: [A, C, B, E]\nlist集合是空的:false\n替换前:[A, C, B, E]\n替换后:[A, F, B, E]\n[]\n```\n### （2）遍历集合\n集合最常用的操作之一是遍历，遍历就是将集合中的每一个元素取出来，进行操作或计算。List集合遍历有三种方法:\n01. 使用for循环遍历:List集合可以使用for循环进行遍历，for循环中有循环变量，通过循环变量可\n以访问List集合中的元素。\n02. 使用for-each循环遍历:for-each循环是针对遍历各种类型集合而推出的，笔者推荐使用这种遍历\n方法。\n03. 使用迭代器遍历:Java提供了多种迭代器，List集合可以使用Iterator和ListIterator迭代器。\n代码如下：\n\n```java\npackage 集合.list集合遍历;\n\nimport java.util.ArrayList;\nimport java.util.Iterator;\nimport java.util.List;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        List list = new ArrayList();\n\n        String b = \"B\";\n//       向集合中添加元素\n        list.add(\"A\");\n        list.add(b);\n        list.add(\"C\");\n        list.add(b);\n        list.add(\"D\");\n        list.add(\"E\");\n\n//        打印集合\n        System.out.println(list);\n//        for循环遍历集合\n        System.out.println(\"--1.使用for循环遍历--\");\n        for (int i = 0;i<list.size();i++){\n//            System.out.println(list.get(i));\n            System.out.printf(\"读取集合元素(%d): %s \\n\", i, list.get(i));\n        }\n        // 2.使用for-each循环遍历\n        System.out.println(\"--2.使用for-each循环遍历--\");\n        for (Object items:list){\n            String s = (String) items;\n            System.out.println(\"读取集合元素：\"+s);\n        }\n\n        // 3.使用迭代器遍历\n        System.out.println(\"--3.使用迭代器遍历--\");\n        Iterator iterator = list.iterator();\n        while (iterator.hasNext()){\n            Object items = iterator.next();\n            String s = (String)items;\n            System.out.println(\"读取集合元素：\"+s);\n        }\n    }\n}\n```\n运行结果：\n\n```java\n[A, B, C, B, D, E]\n--1.使用for循环遍历--\n读取集合元素(0): A \n读取集合元素(1): B \n读取集合元素(2): C \n读取集合元素(3): B \n读取集合元素(4): D \n读取集合元素(5): E \n--2.使用for-each循环遍历--\n读取集合元素：A\n读取集合元素：B\n读取集合元素：C\n读取集合元素：B\n读取集合元素：D\n读取集合元素：E\n--3.使用迭代器遍历--\n读取集合元素：A\n读取集合元素：B\n读取集合元素：C\n读取集合元素：B\n读取集合元素：D\n读取集合元素：E\n```\n## 二、Set集合\nSet集合是由一串无序的，不能重复的相同类型元素构成的集合。List集合强调的是有序，Set集合强调的是不重复。当不考虑顺序，且没有重复元素时，Set集合和List集 合可以互相替换的。Set接口直接实现类主要是HashSet，HashSet是基于散列表数据结构的实现。\n### （1）常用方法\nSet接口也继承自Collection接口，Set接口中大部分都是继承自Collection接口，这些方法如下。\n01. 操作元素\nadd(Object element):在Set集合的尾部添加指定的元素。该方法是从Collection集合继承过来的。\nremove(Object element):如果Set集合中存在指定元素，则从Set集合中移除该元素。该方法是从Collection集合继承过来的。\nclear():从Set集合中移除所有元素。该方法是从Collection集合继承过来的。 \n02. 判断元素\nisEmpty():判断Set集合中是否有元素，没有返回true，有返回false。该方法是从 Collection集合继承过来的。\ncontains(Object element):判断Set集合中是否包含指定元素，包含返回true，不包含返回 false。该方法是从Collection集合继承过来的。\n03. 其他\niterator():返回迭代器(Iterator)对象，迭代器对象用于遍历集合。该方法是从Collection\n集合继承过来的。\nsize():返回Set集合中的元素数，返回值是int类型。该方法是从Collection集合继承过来的。\n代码如下：\n\n```java\n//set集合：无序，不重复\nimport java.util.HashSet;\n\npublic class Set {\n    public static void main(String[] args) {\n        java.util.Set set = new HashSet();\n\n        String b = \"B\";\n// 向集合中添加元素\n        set.add(\"A\");\n        set.add(b);\n        set.add(\"C\");\n        set.add(b);\n        set.add(\"D\");\n        set.add(\"E\");\n//        打印集合个数\n        System.out.println(\"集合size = \"+set.size());\n//        打印集合\n        System.out.println(set);\n//       删除集合中的B元素\n        set.remove(b);\n//        判断集合中是否包含\"B\"元素\n        System.out.println(\"判断是否包含B元素\"+set.contains(b));\n//        判断集合是否为空\n        System.out.println(\"判断集合是否为空\"+set.isEmpty());\n//        清空集合\n        set.clear();\n        //        打印集合\n        System.out.println(set);\n    }\n}\n```\n运行结果：\n\n```java\n集合size = 5\n[A, B, C, D, E]\n判断是否包含B元素false\n判断集合是否为空false\n[]\n```\n### （2）遍历集合\nSet集合中的元素由于没有序号，所以不能使用for循环进行遍历，但可以使用for-each循环和迭代器进 行遍历。事实上这两种遍历方法也是继承自Collection集合，也就是说所有的Collection集合类型都有这 两种遍历方式。\n代码如下：\n\n```java\npublic class Bianli {\n    public static void main(String[] args) {\n        Set set = new HashSet();\n        String b = \"B\";\n// 向集合中添加元素\n        set.add(\"A\");\n        set.add(b);\n        set.add(\"C\");\n        set.add(b);\n        set.add(\"D\");\n        set.add(\"E\");\n\n        //        打印集合\n        System.out.println(set);\n//        1，使用增强for遍历\n        System.out.println(\"--1，使用增强for遍历--\");\n        for (Object item : set){\n            String s = (String)item;\n            System.out.println(s);\n        }\n//        2.使用迭代器遍历集合\n        System.out.println(\"--2.使用迭代器遍历集合--\");\n        Iterator iterator = set.iterator();\n        while (iterator.hasNext()){\n            Object item  = iterator.next();\n            String s = (String)item;\n            System.out.println(\"读取集合\"+s);\n        }\n\n    }\n}\n```\n运行结果：\n\n```java\n[A, B, C, D, E]\n--1，使用增强for遍历--\nA\nB\nC\nD\nE\n--2.使用迭代器遍历集合--\n读取集合A\n读取集合B\n读取集合C\n读取集合D\n读取集合E\n```\n## 三、Map集合\nMap(映射)集合表示一种非常复杂的集合，允许按照某个键来访问元素。Map集合是由两个集合构 成的，一个是键(key)集合，一个是值(value)集合。键集合是Set类型，因此不能有重复的元素。 而值集合是Collection类型，可以有重复的元素。Map集合中的键和值是成对出现的。Map接口直接实现类主要是HashMap，HashMap是基于散列表数据结构的实现。\n### （1）常用方法\nMap集合中包含两个集合(键和值)，所以操作起来比较麻烦，Map接口提供很多方法用来管理和操 作集合。主要的方法如下。\n01. 操作元素\nget(Object key):返回指定键所对应的值;如果Map集合中不包含该键值对，则返回null。 put(Object key, Object value):指定键值对添加到集合中。\nremove(Object key):移除键值对。\nclear():移除Map集合中所有键值对。 \n02. 判断元素\nisEmpty():判断Map集合中是否有键值对，没有返回true，有返回false。 \ncontainsKey(Object key):判断键集合中是否包含指定元素，包含返回true，不包含返回false。\ncontainsValue(Object value):判断值集合中是否包含指定元素，包含返回true，不包含返回false。\n03. 查看集合\nkeySet():返回Map中的所有键集合，返回值是Set类型。 \nvalues():返回Map中的所有值集合，返回值是Collection类型。 \nsize():返回Map集合中键值对数。\n代码如下：\n\n```java\npackage 集合.map集合;\n\nimport java.util.HashMap;\n\npublic class Map {\n    public static void main(String[] args) {\n        java.util.Map map = new HashMap();\n\n        map.put(101,\"A\");\n        map.put(102, \"B\");\n        map.put(103, \"C\");\n        map.put(104, \"D\");\n//        B重复\n        map.put(105, \"B\");\n//把102的值换成E\n        map.put(102, \"E\");\n//        打印集合\n        System.out.println(map);\n//        打印集合元素个数\n        System.out.println(\"集合size=\"+map.size());\n//        通过键取值\n        System.out.println(\"102-\"+map.get(102));\n        System.out.println(\"105-\"+map.get(105));\n//        删除键值对\n        map.remove(102);\n        System.out.println(map);\n//        判断集合中是否包含105\n        System.out.println(\"集合中是否包含102\"+map.containsKey(105));\n//        集合中是否包含\"A\"\n        System.out.println(\"集合中是否包含A\"+map.containsValue(\"A\"));\n//        判断集合是否为空\n        System.out.println(\"集合是否为空\"+map.isEmpty());\n//        清空集合\n        map.clear();\n        System.out.println(map);\n    }\n}\n```\n运行结果：\n\n```java\n{101=A, 102=E, 103=C, 104=D, 105=B}\n集合size=5\n102-E\n105-B\n{101=A, 103=C, 104=D, 105=B}\n集合中是否包含102true\n集合中是否包含Atrue\n集合是否为空false\n{}\n```\n### （2）遍历集合\nMap集合遍历与List和Set集合不同，Map有两个集合，因此遍历时可以只遍历值的集合，也可以只遍历键的集合，也可以同时遍历。这些遍历过程都可以使用for-each循环和迭代器进行遍历。\n代码如下：\n\n```java\npackage 集合.map集合遍历;\n\nimport java.util.*;\n\npublic class Mapbianli {\n    public static void main(String[] args) {\n        Map map = new HashMap();\n        map.put(101,\"A\");\n        map.put(102, \"B\");\n        map.put(103, \"C\");\n        map.put(104, \"D\");\n//        使用增强for循环遍历\n        System.out.println(\"使用增强for循环遍历\");\n//        获得键集合\n        Set keys  = map.keySet();\n        for (Object key:keys){\n//            自动拆箱\n            int ikey = (Integer) key;\n//            自动装箱\n            String value = (String)map.get(ikey);\n            System.out.printf(\"key=%d-value=%s \\n\",ikey,value);\n        }\n//        使用迭代器遍历集合\n        System.out.println(\"使用迭代器遍历集合\");\n//        获得值集合\n        Collection values = map.values();\n//        遍历值集合\n        Iterator iterator = values.iterator();\n        while (iterator.hasNext()){\n            Object item = iterator.next();\n            String s = (String)item;\n            System.out.println(\"集合元素集合:\"+s);\n        }\n    }\n}\n```\n运行结果：\n\n```java\n使用增强for循环遍历\nkey=101-value=A \nkey=102-value=B \nkey=103-value=C \nkey=104-value=D \n使用迭代器遍历集合\n集合元素集合:A\n集合元素集合:B\n集合元素集合:C\n集合元素集合:D\n```","tags":["Java"],"categories":["Java基础语法"]},{"title":"Java面试题实现线程的几种方式？","url":"/posts/3425737821/","content":"在Java面试中面试官常常会问这样一道面试题：Java面试题实现线程的几种方式？\n这道题看似简单也会难道很多人，下面总结一些实现线程的几种方式。\n<!-- more --> \n第一种：通过实现Runnable接口\n创建步骤：\n\n - 1、通过实现Runnable接口创建线程执行类 \n - 2、通过重写Runnable中的run方法，编写线程执行代码\n - 3、创建线程Thread对象，将线程执行对象传递给它 \n - 4、开始线程\n\n第二种：通过继承Thread线程类\n创建步骤：\n\n - 1、通过继承Thread线程类创建线程执行类 \n - 2、定义构造方法，通过super调用父类Thread构造方法 这两个Thread类\n   构造方法:\n   \n   Thread(String name):name为线程指定一个名字。 \n   Thread():线程名字是JVM分配的。\n   \n - 3、通过重写Thread中的run方法，编写线程执行代码 \n - 4、创建线程执行对象，将参数传递给它 \n - 5、开始线程\n\n示例代码：\n\n```java\nclass DogThread extends Thread{\n    @Override\n    public void run(){\n        System.out.println(\"dog eat\");\n    }\n}\n\nclass CatRunnable implements Runnable{\n    @Override\n    public void run() {\n        System.out.println(\"cat eat\");\n    }\n}\n\npublic class TestThread {\n    public static void main(String[] args) {\n        // 方案一：\n        DogThread dogThread = new DogThread();\n        dogThread.start();\n\n        // 方案二：\n        Thread thread = new Thread(new CatRunnable());\n        thread.start();\n\n//        使用内部类写法\n        Thread t1 = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                System.out.println(\"cat eat\");\n            }\n        });\n        t1.start();\n\n//        使用lambda表达式写法\n        Thread t2 = new Thread(() ->{\n            System.out.println(\"cat eat\");\n        });\n        t2.start();\n    }\n}\n```\n运行结果：\n\n```java\ndog eat\ncat eat\ncat eat\ncat eat\n```\n关于线程的更多知识点见这篇文章[https://blog.csdn.net/weixin_45366499/article/details/104346644](https://blog.csdn.net/weixin_45366499/article/details/104346644)\n","tags":["Java"],"categories":["Java面试指南"]}]